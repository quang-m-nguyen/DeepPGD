{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3638,"status":"ok","timestamp":1727249124927,"user":{"displayName":"Quang Nguyen","userId":"15371400332849231940"},"user_tz":-420},"id":"Bmz33f_KotBp","outputId":"f438c561-cdde-4024-a9ac-71d2495e634b"},"outputs":[],"source":["# !pip install pandas numpy tensorflow transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29031,"status":"ok","timestamp":1727249153954,"user":{"displayName":"Quang Nguyen","userId":"15371400332849231940"},"user_tz":-420},"id":"0Ah7qBIWou29","outputId":"00df7916-089b-4527-fb19-c2401d51c68f"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8437,"status":"ok","timestamp":1727249162388,"user":{"displayName":"Quang Nguyen","userId":"15371400332849231940"},"user_tz":-420},"id":"KR0Os0MVotBp"},"outputs":[],"source":["import tensorflow as tf\n","from transformers import TFBertModel, AutoTokenizer\n","import pandas as pd\n","import numpy as np\n","\n","def load_data(tsv_file):\n","    \"\"\"\n","    Load sequences and labels from a TSV file.\n","    Args:\n","        tsv_file (str): Path to the TSV file.\n","    Returns:\n","        sequences (List[str]): List of DNA sequences.\n","        labels (List[int]): List of labels (0 or 1).\n","    \"\"\"\n","    df = pd.read_csv(tsv_file, sep='\\t')\n","    sequences = df['text'].tolist()\n","    labels = df['label'].tolist()\n","    return sequences, labels\n","\n","def tokenize_sequences(sequences, tokenizer, max_length=64):\n","    \"\"\"\n","    Tokenize DNA sequences using DNABERT2 tokenizer.\n","    Args:\n","        sequences (List[str]): List of DNA sequences.\n","        tokenizer: Tokenizer object.\n","        max_length (int): Maximum sequence length.\n","    Returns:\n","        input_ids, attention_mask\n","    \"\"\"\n","    encodings = tokenizer(\n","        sequences,\n","        padding='max_length',\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors='tf'\n","    )\n","    return encodings['input_ids'], encodings['attention_mask']\n","\n","class DNABERTClassifier(tf.keras.Model):\n","    def __init__(self, pretrained_model_name_or_path, max_length=64):\n","        super(DNABERTClassifier, self).__init__()\n","        self.bert = TFBertModel.from_pretrained(\n","            pretrained_model_name_or_path,\n","            from_pt=True,\n","            trust_remote_code=True\n","        )\n","        self.dropout1 = tf.keras.layers.Dropout(0.3)\n","        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n","        self.dropout2 = tf.keras.layers.Dropout(0.3)\n","        self.dense2 = tf.keras.layers.Dense(256, activation='relu')\n","        self.dropout3 = tf.keras.layers.Dropout(0.3)\n","        self.dense3 = tf.keras.layers.Dense(64, activation='relu')\n","        self.dropout4 = tf.keras.layers.Dropout(0.3)\n","        self.output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n","\n","    def call(self, inputs, training=False):\n","        input_ids = inputs['input_ids']\n","        attention_mask = inputs['attention_mask']\n","        \n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output  # [batch_size, hidden_size]\n","        \n","        logits = self.output_layer(pooled_output)\n","\n","        return logits\n","\n","def build_dnabert_classification_model(pretrained_model_name_or_path, max_length=64):\n","    \"\"\"\n","    Build a DNABERT2 model for binary classification with additional layers\n","    using the Keras Subclassing API.\n","\n","    Args:\n","        pretrained_model_name_or_path (str): Name or path of the pretrained DNABERT2 model.\n","        max_length (int): Maximum sequence length.\n","\n","    Returns:\n","        model (tf.keras.Model): A compiled Keras model ready for training.\n","    \"\"\"\n","    # Instantiate the model\n","    model = DNABERTClassifier(pretrained_model_name_or_path, max_length)\n","\n","    # Compile the model\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n","        loss=tf.keras.losses.BinaryCrossentropy(),\n","        metrics=['accuracy']\n","    )\n","\n","    return model\n","\n","def train_dnabert_finetuning_model(\n","    train_tsv,\n","    val_tsv,\n","    pretrained_model_name_or_path='zhihan1996/DNABERT-2-117M',\n","    max_length=64,\n","    epochs=30,\n","    batch_size=256\n","):\n","    \"\"\"\n","    Fine-tune DNABERT2 for binary classification with additional layers.\n","\n","    Args:\n","        train_tsv (str): Path to the training TSV file.\n","        val_tsv (str): Path to the validation TSV file.\n","        pretrained_model_name_or_path (str): DNABERT2 model identifier.\n","        max_length (int): Maximum sequence length for tokenization.\n","        epochs (int): Number of training epochs.\n","        batch_size (int): Training batch size.\n","\n","    Returns:\n","        model (tf.keras.Model): The trained model.\n","    \"\"\"\n","    # Load tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        pretrained_model_name_or_path,\n","        trust_remote_code=True\n","    )\n","\n","    # Load and tokenize training data\n","    X_train_sequences, y_train = load_data(train_tsv)\n","    X_train_input_ids, X_train_attention_mask = tokenize_sequences(\n","        X_train_sequences, tokenizer, max_length\n","    )\n","    y_train = np.array(y_train).astype('float32')\n","\n","    # Load and tokenize validation data\n","    X_val_sequences, y_val = load_data(val_tsv)\n","    X_val_input_ids, X_val_attention_mask = tokenize_sequences(\n","        X_val_sequences, tokenizer, max_length\n","    )\n","    y_val = np.array(y_val).astype('float32')\n","\n","    # Build the model\n","    model = build_dnabert_classification_model(\n","        pretrained_model_name_or_path, max_length\n","    )\n","\n","    # Callbacks\n","    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n","    model_checkpoint = ModelCheckpoint(\n","        'best_model.keras',\n","        monitor='val_accuracy',\n","        save_best_only=True,\n","        mode='max'\n","    )\n","\n","    # Train the model\n","    history = model.fit(\n","        x={\n","            'input_ids': X_train_input_ids,\n","            'attention_mask': X_train_attention_mask\n","        },\n","        y=y_train,\n","        validation_data=(\n","            {\n","                'input_ids': X_val_input_ids,\n","                'attention_mask': X_val_attention_mask\n","            },\n","            y_val\n","        ),\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        callbacks=[early_stopping, model_checkpoint],\n","    )\n","\n","    # Load the best model\n","    model.load_weights('best_model.keras')\n","\n","    return model"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b84907b56cf949158310a45c762a4150","14b536ef9f754ab6be6d673844479b82","1f99864efe3146e1bdfc74a0f4c8d09b","bf354d49403e48aa86226ebbd00c5fe7","2987c75615f5413f889b978ac0b418ed","97d2ec4ddfe14e7d88212e6794da9b08","c91dddafd06a4c0f92786920a8b6a6db","0b5794ea6c0943d9a4cbca3ed7fa0e05","99cdab5859874b87ae38de093917be91","f189d1bfa95342acbaaaee7acaedf623","2532bc0ef76e4b938f0c0f86cc1afb52","b79e6a8e14de4cd0a6cc10a839e4934a","4facdaf533d6480a8cb578a4dac4d850","77647b877dbb4d63a531260b4607dd1f","435ceedbb674436993962e66804e1e3d","3829e9a2ba8d46ea970871a3e61ca92f","d565df96318549c5a94f97a544ebfaae","d5e93827b48d42daa704222b4106400b","b99144bacc8e49eaa0ef79fa7289a2ef","dc6848180f024b5c8d9e03ef2d2c570c","d2950a23c11d4e66b86bfdf494f7d057","4213b2004d5646628f63ba7902c54346","a3a138b7eb0f40b0934f89c44134d247","c0897780009c4550bb6fcdb69eea9574","b27483eb12ec436e8c2273e0b6b3fcc3","607f16a597934eaa86c5842e36e94f45","9f35587349d74c958c1632b544a382e4","c588dbeb2eb94b3ab381d841b7c01e98","bdd59a5bf2034748a866bea03a3fb1e1","f38ca9df9c1c4d8a8b8547040694d3c4","331e86ba8cc24a86895ca61e847d335d","5bb6f3fadaa047748741d08da4fe460f","a92e59ee56fc42178e7dcb2e0d993e30","329c41f69369463887889f9ec9db4824","a7c142511abe420598f279722085a760","9b66ae366b96422fb57a249c01c4dde9","064472daa96a4a2fa7ff027cd9d69af3","e1cfc7aa51a744fbadfd384976ca60d8","13381869d96f493e96aa8adfd34fc56e","6811141d116d4fa2af591ddcec00739c","41524d82b2184e8287dd9a6ca9e1fed2","932c4f46df484c709441cdee6f8219b5","ff3a8b9c12cb4baf937e4cf36d479a0d","883f515be9b04cfa87a9db319bf8c0fe"]},"id":"_CQnXP0TotBq","outputId":"535f2273-1e74-46a7-da4e-7b9e5fa84501"},"outputs":[{"name":"stderr","output_type":"stream","text":["The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['bert.encoder.layer.8.mlp.wo.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.5.attention.self.Wqkv.weight', 'bert.encoder.layer.6.mlp.wo.bias', 'bert.encoder.layer.4.mlp.layernorm.bias', 'bert.encoder.layer.6.mlp.gated_layers.weight', 'bert.encoder.layer.3.mlp.layernorm.weight', 'bert.encoder.layer.2.attention.self.Wqkv.weight', 'bert.encoder.layer.3.mlp.wo.bias', 'bert.encoder.layer.0.attention.self.Wqkv.bias', 'bert.encoder.layer.5.mlp.gated_layers.weight', 'bert.encoder.layer.1.mlp.gated_layers.weight', 'bert.encoder.layer.1.mlp.wo.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.11.mlp.layernorm.bias', 'bert.encoder.layer.3.attention.self.Wqkv.bias', 'bert.encoder.layer.8.mlp.gated_layers.weight', 'bert.encoder.layer.11.mlp.wo.bias', 'bert.encoder.layer.2.mlp.layernorm.bias', 'bert.encoder.layer.7.mlp.wo.bias', 'bert.encoder.layer.4.attention.self.Wqkv.bias', 'bert.encoder.layer.4.mlp.layernorm.weight', 'bert.encoder.layer.1.attention.self.Wqkv.bias', 'bert.encoder.layer.0.mlp.layernorm.bias', 'bert.encoder.layer.9.attention.self.Wqkv.weight', 'bert.encoder.layer.4.mlp.wo.weight', 'bert.encoder.layer.2.mlp.layernorm.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.3.mlp.gated_layers.weight', 'bert.encoder.layer.5.attention.self.Wqkv.bias', 'bert.encoder.layer.8.mlp.layernorm.weight', 'bert.encoder.layer.8.mlp.wo.bias', 'bert.encoder.layer.5.mlp.layernorm.bias', 'bert.encoder.layer.3.mlp.wo.weight', 'bert.encoder.layer.9.mlp.wo.bias', 'bert.encoder.layer.11.mlp.gated_layers.weight', 'bert.encoder.layer.11.attention.self.Wqkv.bias', 'bert.encoder.layer.7.attention.self.Wqkv.weight', 'bert.encoder.layer.6.attention.self.Wqkv.bias', 'bert.encoder.layer.9.attention.self.Wqkv.bias', 'bert.encoder.layer.4.attention.self.Wqkv.weight', 'bert.encoder.layer.10.mlp.gated_layers.weight', 'bert.encoder.layer.10.attention.self.Wqkv.bias', 'bert.encoder.layer.6.mlp.layernorm.bias', 'bert.encoder.layer.1.attention.self.Wqkv.weight', 'bert.encoder.layer.8.attention.self.Wqkv.bias', 'bert.encoder.layer.10.mlp.layernorm.weight', 'bert.encoder.layer.8.attention.self.Wqkv.weight', 'bert.encoder.layer.5.mlp.wo.bias', 'bert.encoder.layer.7.attention.self.Wqkv.bias', 'bert.encoder.layer.9.mlp.wo.weight', 'bert.encoder.layer.2.mlp.wo.weight', 'bert.encoder.layer.6.attention.self.Wqkv.weight', 'bert.encoder.layer.5.mlp.wo.weight', 'bert.encoder.layer.6.mlp.layernorm.weight', 'bert.encoder.layer.10.mlp.layernorm.bias', 'bert.encoder.layer.0.mlp.wo.weight', 'bert.encoder.layer.9.mlp.layernorm.weight', 'bert.encoder.layer.7.mlp.wo.weight', 'bert.encoder.layer.7.mlp.layernorm.weight', 'bert.encoder.layer.10.attention.self.Wqkv.weight', 'bert.encoder.layer.6.mlp.wo.weight', 'bert.encoder.layer.0.mlp.wo.bias', 'bert.encoder.layer.8.mlp.layernorm.bias', 'bert.encoder.layer.3.attention.self.Wqkv.weight', 'bert.encoder.layer.11.mlp.wo.weight', 'bert.encoder.layer.4.mlp.gated_layers.weight', 'bert.encoder.layer.11.attention.self.Wqkv.weight', 'bert.encoder.layer.1.mlp.layernorm.weight', 'bert.encoder.layer.2.mlp.wo.bias', 'bert.encoder.layer.7.mlp.gated_layers.weight', 'bert.encoder.layer.3.mlp.layernorm.bias', 'bert.encoder.layer.9.mlp.gated_layers.weight', 'bert.encoder.layer.4.mlp.wo.bias', 'bert.encoder.layer.1.mlp.layernorm.bias', 'bert.encoder.layer.7.mlp.layernorm.bias', 'bert.encoder.layer.0.mlp.layernorm.weight', 'bert.encoder.layer.0.mlp.gated_layers.weight', 'bert.encoder.layer.5.mlp.layernorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'bert.encoder.layer.10.mlp.wo.bias', 'bert.encoder.layer.11.mlp.layernorm.weight', 'bert.encoder.layer.1.mlp.wo.bias', 'bert.encoder.layer.2.attention.self.Wqkv.bias', 'bert.encoder.layer.2.mlp.gated_layers.weight', 'bert.encoder.layer.9.mlp.layernorm.bias', 'bert.encoder.layer.10.mlp.wo.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.0.attention.self.Wqkv.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'dnabert_classifier_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n","W0000 00:00:1727505246.668894   60184 assert_op.cc:38] Ignoring Assert operator dnabert_classifier_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.5067 - loss: 0.7565"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1727505263.503624   60187 assert_op.cc:38] Ignoring Assert operator dnabert_classifier_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.5067 - loss: 0.7565"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1727505269.543502   60183 assert_op.cc:38] Ignoring Assert operator dnabert_classifier_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n","W0000 00:00:1727505284.790949   60185 assert_op.cc:38] Ignoring Assert operator dnabert_classifier_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 596ms/step - accuracy: 0.5066 - loss: 0.7564 - val_accuracy: 0.5000 - val_loss: 0.7271\n","Epoch 2/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 403ms/step - accuracy: 0.5005 - loss: 0.7385 - val_accuracy: 0.5000 - val_loss: 0.7120\n","Epoch 3/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 412ms/step - accuracy: 0.4976 - loss: 0.7268 - val_accuracy: 0.4999 - val_loss: 0.7030\n","Epoch 4/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 419ms/step - accuracy: 0.4951 - loss: 0.7191 - val_accuracy: 0.4998 - val_loss: 0.6979\n","Epoch 5/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 425ms/step - accuracy: 0.5048 - loss: 0.7121 - val_accuracy: 0.5041 - val_loss: 0.6953\n","Epoch 6/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 430ms/step - accuracy: 0.5011 - loss: 0.7117 - val_accuracy: 0.5028 - val_loss: 0.6939\n","Epoch 7/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 423ms/step - accuracy: 0.5021 - loss: 0.7095 - val_accuracy: 0.5084 - val_loss: 0.6934\n","Epoch 8/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 424ms/step - accuracy: 0.4978 - loss: 0.7129 - val_accuracy: 0.5096 - val_loss: 0.6931\n","Epoch 9/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 425ms/step - accuracy: 0.5099 - loss: 0.7080 - val_accuracy: 0.5097 - val_loss: 0.6929\n","Epoch 10/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 426ms/step - accuracy: 0.4940 - loss: 0.7110 - val_accuracy: 0.5110 - val_loss: 0.6928\n","Epoch 11/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 425ms/step - accuracy: 0.4965 - loss: 0.7099 - val_accuracy: 0.5125 - val_loss: 0.6927\n","Epoch 12/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 424ms/step - accuracy: 0.5023 - loss: 0.7086 - val_accuracy: 0.5137 - val_loss: 0.6925\n","Epoch 13/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 425ms/step - accuracy: 0.5139 - loss: 0.7058 - val_accuracy: 0.5153 - val_loss: 0.6924\n","Epoch 14/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 425ms/step - accuracy: 0.5068 - loss: 0.7081 - val_accuracy: 0.5165 - val_loss: 0.6923\n","Epoch 15/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 426ms/step - accuracy: 0.5030 - loss: 0.7089 - val_accuracy: 0.5186 - val_loss: 0.6922\n","Epoch 16/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 424ms/step - accuracy: 0.4931 - loss: 0.7111 - val_accuracy: 0.5201 - val_loss: 0.6921\n","Epoch 17/30\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5011 - loss: 0.7107"]}],"source":["train_tsv = '/teamspace/studios/this_studio/train-data/train.tsv'  # Update this path\n","val_tsv = '/teamspace/studios/this_studio/train-data/test.tsv'  # Update this path\n","model = train_dnabert_finetuning_model(\n","    train_tsv,\n","    val_tsv,\n","    pretrained_model_name_or_path='zhihan1996/DNABERT-2-117M',\n","    max_length=64,\n","    epochs=30,\n","    batch_size=256\n",")\n","# Save the trained model\n","model.save('/teamspace/studios/this_studio/DeepPGD/dnabert_finetuned_model.keras')\n","\n","\n","print(\"Model training completed and saved.\")\n","\n","# Optional: Evaluate the model on the validation set\n","X_val_sequences, y_val = load_data(val_tsv)\n","tokenizer = AutoTokenizer.from_pretrained('zhihan1996/DNABERT-2-117M', trust_remote_code=True)\n","X_val_input_ids, X_val_attention_mask = tokenize_sequences(X_val_sequences, tokenizer, max_length=64)\n","y_val = np.array(y_val).astype('float32')\n","\n","evaluation = model.evaluate(\n","    x={'input_ids': X_val_input_ids, 'attention_mask': X_val_attention_mask},\n","    y=y_val\n",")\n","print(f\"Validation Loss: {evaluation[0]:.4f}\")\n","print(f\"Validation Accuracy: {evaluation[1]:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzoZk_wGpzI1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[{"file_id":"https://github.com/quang-m-nguyen/DeepPGD/blob/main/bert-finetuning.ipynb","timestamp":1726622193532}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"064472daa96a4a2fa7ff027cd9d69af3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff3a8b9c12cb4baf937e4cf36d479a0d","placeholder":"​","style":"IPY_MODEL_883f515be9b04cfa87a9db319bf8c0fe","value":" 468M/468M [00:05&lt;00:00, 189MB/s]"}},"0b5794ea6c0943d9a4cbca3ed7fa0e05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13381869d96f493e96aa8adfd34fc56e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14b536ef9f754ab6be6d673844479b82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97d2ec4ddfe14e7d88212e6794da9b08","placeholder":"​","style":"IPY_MODEL_c91dddafd06a4c0f92786920a8b6a6db","value":"tokenizer_config.json: 100%"}},"1f99864efe3146e1bdfc74a0f4c8d09b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b5794ea6c0943d9a4cbca3ed7fa0e05","max":158,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99cdab5859874b87ae38de093917be91","value":158}},"2532bc0ef76e4b938f0c0f86cc1afb52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2987c75615f5413f889b978ac0b418ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329c41f69369463887889f9ec9db4824":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7c142511abe420598f279722085a760","IPY_MODEL_9b66ae366b96422fb57a249c01c4dde9","IPY_MODEL_064472daa96a4a2fa7ff027cd9d69af3"],"layout":"IPY_MODEL_e1cfc7aa51a744fbadfd384976ca60d8"}},"331e86ba8cc24a86895ca61e847d335d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3829e9a2ba8d46ea970871a3e61ca92f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41524d82b2184e8287dd9a6ca9e1fed2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4213b2004d5646628f63ba7902c54346":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"435ceedbb674436993962e66804e1e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2950a23c11d4e66b86bfdf494f7d057","placeholder":"​","style":"IPY_MODEL_4213b2004d5646628f63ba7902c54346","value":" 168k/168k [00:00&lt;00:00, 2.29MB/s]"}},"4facdaf533d6480a8cb578a4dac4d850":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d565df96318549c5a94f97a544ebfaae","placeholder":"​","style":"IPY_MODEL_d5e93827b48d42daa704222b4106400b","value":"tokenizer.json: 100%"}},"5bb6f3fadaa047748741d08da4fe460f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"607f16a597934eaa86c5842e36e94f45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bb6f3fadaa047748741d08da4fe460f","placeholder":"​","style":"IPY_MODEL_a92e59ee56fc42178e7dcb2e0d993e30","value":" 904/904 [00:00&lt;00:00, 72.8kB/s]"}},"6811141d116d4fa2af591ddcec00739c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77647b877dbb4d63a531260b4607dd1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b99144bacc8e49eaa0ef79fa7289a2ef","max":167908,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc6848180f024b5c8d9e03ef2d2c570c","value":167908}},"883f515be9b04cfa87a9db319bf8c0fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"932c4f46df484c709441cdee6f8219b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97d2ec4ddfe14e7d88212e6794da9b08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99cdab5859874b87ae38de093917be91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b66ae366b96422fb57a249c01c4dde9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41524d82b2184e8287dd9a6ca9e1fed2","max":468354983,"min":0,"orientation":"horizontal","style":"IPY_MODEL_932c4f46df484c709441cdee6f8219b5","value":468354983}},"9f35587349d74c958c1632b544a382e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3a138b7eb0f40b0934f89c44134d247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0897780009c4550bb6fcdb69eea9574","IPY_MODEL_b27483eb12ec436e8c2273e0b6b3fcc3","IPY_MODEL_607f16a597934eaa86c5842e36e94f45"],"layout":"IPY_MODEL_9f35587349d74c958c1632b544a382e4"}},"a7c142511abe420598f279722085a760":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13381869d96f493e96aa8adfd34fc56e","placeholder":"​","style":"IPY_MODEL_6811141d116d4fa2af591ddcec00739c","value":"pytorch_model.bin: 100%"}},"a92e59ee56fc42178e7dcb2e0d993e30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b27483eb12ec436e8c2273e0b6b3fcc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f38ca9df9c1c4d8a8b8547040694d3c4","max":904,"min":0,"orientation":"horizontal","style":"IPY_MODEL_331e86ba8cc24a86895ca61e847d335d","value":904}},"b79e6a8e14de4cd0a6cc10a839e4934a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4facdaf533d6480a8cb578a4dac4d850","IPY_MODEL_77647b877dbb4d63a531260b4607dd1f","IPY_MODEL_435ceedbb674436993962e66804e1e3d"],"layout":"IPY_MODEL_3829e9a2ba8d46ea970871a3e61ca92f"}},"b84907b56cf949158310a45c762a4150":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14b536ef9f754ab6be6d673844479b82","IPY_MODEL_1f99864efe3146e1bdfc74a0f4c8d09b","IPY_MODEL_bf354d49403e48aa86226ebbd00c5fe7"],"layout":"IPY_MODEL_2987c75615f5413f889b978ac0b418ed"}},"b99144bacc8e49eaa0ef79fa7289a2ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdd59a5bf2034748a866bea03a3fb1e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf354d49403e48aa86226ebbd00c5fe7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f189d1bfa95342acbaaaee7acaedf623","placeholder":"​","style":"IPY_MODEL_2532bc0ef76e4b938f0c0f86cc1afb52","value":" 158/158 [00:00&lt;00:00, 12.0kB/s]"}},"c0897780009c4550bb6fcdb69eea9574":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c588dbeb2eb94b3ab381d841b7c01e98","placeholder":"​","style":"IPY_MODEL_bdd59a5bf2034748a866bea03a3fb1e1","value":"config.json: 100%"}},"c588dbeb2eb94b3ab381d841b7c01e98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c91dddafd06a4c0f92786920a8b6a6db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2950a23c11d4e66b86bfdf494f7d057":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d565df96318549c5a94f97a544ebfaae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5e93827b48d42daa704222b4106400b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc6848180f024b5c8d9e03ef2d2c570c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1cfc7aa51a744fbadfd384976ca60d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f189d1bfa95342acbaaaee7acaedf623":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f38ca9df9c1c4d8a8b8547040694d3c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff3a8b9c12cb4baf937e4cf36d479a0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}

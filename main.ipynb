{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quang-m-nguyen/DeepPGD/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ImeIY8CbpXP",
        "outputId": "ac459578-0c55-4561-fb06-e10805e58f58"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "24WMAyCfLp_2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "# from keras_self_attention import SeqSelfAttention\n",
        "# from keras.utils import to_categorical\n",
        "from keras.layers import (\n",
        "    Bidirectional,\n",
        "    Conv1D,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Embedding,\n",
        "    Flatten,\n",
        "    Input,\n",
        "    LayerNormalization,\n",
        "    concatenate,\n",
        "    LSTM\n",
        ")\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
        "from tensorflow.keras import initializers, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global x_test, y_test, x_train, y_train\n",
        "# global best_acc\n",
        "# global accuracy_best_list\n",
        "\n",
        "# # make all of these variable global\n",
        "# # global x_test, y_test, x_train, y_train\n",
        "# # global best_acc\n",
        "# # global accuracy_best_list\n",
        "\n"
      ],
      "metadata": {
        "id": "PtSEWOkJoFQM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_training_data():\n",
        "    train_filename = '/content/drive/MyDrive/deepPGD/4mC/4mC_C.equisetifolia/train.tsv'\n",
        "    test_filename = '/content/drive/MyDrive/deepPGD/4mC/4mC_F.vesca/test.tsv'\n",
        "\n",
        "    x_test = np.array([])\n",
        "    y_test = np.array([])\n",
        "    x_train = np.array([])\n",
        "    y_train = np.array([])\n",
        "\n",
        "    test_labels = []\n",
        "    three_er_list = []\n",
        "\n",
        "    K_MER = 3\n",
        "\n",
        "\n",
        "    train_data = pd.read_csv(train_filename,header = None, sep = \"\\t\")\n",
        "    test_data  = pd.read_csv(test_filename,header = None, sep = \"\\t\")\n",
        "\n",
        "    pro_x_train = train_data[2][1:]\n",
        "    y_train =  train_data[1][:]\n",
        "    pos_train_len = len(pro_x_train)\n",
        "\n",
        "    pro_x_test =  test_data[2][1:]\n",
        "    y_test = test_data[1][:]\n",
        "\n",
        "    pro_x_data  = pd.concat([pro_x_train,pro_x_test],ignore_index= True )\n",
        "    pro_y_data  = pd.concat([y_train,y_test],ignore_index= True )\n",
        "\n",
        "\n",
        "    for i in range(1, len(pro_y_data)):\n",
        "      if(pro_y_data[i] == \"1\"):\n",
        "          test_labels.append([1,0])\n",
        "      elif(pro_y_data[i] == \"0\"):\n",
        "          test_labels.append([0,1])\n",
        "      else:\n",
        "          continue\n",
        "\n",
        "    # K-mer Encoding for DNA Sequences\n",
        "    #\n",
        "    # Purpose:\n",
        "    # - Transform variable-length DNA sequences into fixed-length feature representations\n",
        "    # - Capture local sequence patterns that may be relevant to DNA methylation sites\n",
        "    # - Create a suitable input format for machine learning models\n",
        "    #\n",
        "    # Functionality:\n",
        "    # 1. Set k-mer size (K=3 in this case)\n",
        "    # 2. For each DNA sequence:\n",
        "    #    a. Convert to string and remove any extra characters\n",
        "    #    b. Generate all possible k-mers (substrings of length K)\n",
        "    #    c. Store k-mers for each sequence in a list\n",
        "    # 3. Collect k-mer lists for all sequences in str_array\n",
        "    #\n",
        "    # Benefits:\n",
        "    # - Captures local sequence context\n",
        "    # - Provides fixed-length representation for variable-length sequences\n",
        "    # - Reduces sequence complexity while retaining important features\n",
        "    # - Facilitates efficient sequence comparison and analysis\n",
        "    # - Improves feature extraction for machine learning models\n",
        "    #\n",
        "    # Example:\n",
        "    # Input DNA sequence: \"ATCGATCG\"\n",
        "    # Resulting k-mers (K=3): [\"ATC\", \"TCG\", \"CGA\", \"GAT\", \"ATC\", \"TCG\"]\n",
        "    #\n",
        "    # Data structure:\n",
        "    # str_array = [\n",
        "    #     [\"ATC\", \"TCG\", \"CGA\", \"GAT\", \"ATC\", \"TCG\"],\n",
        "    # ]\n",
        "\n",
        "    for i in pro_x_data:\n",
        "        seq_str = str(i)\n",
        "        seq_str = seq_str.strip('[]\\'')\n",
        "        t=0\n",
        "        l=[]\n",
        "        for index in range(len(seq_str)):\n",
        "            t=seq_str[index:index+K_MER]\n",
        "            if (len(t))==K_MER:\n",
        "                l.append(t)\n",
        "        three_er_list.append(l)\n",
        "\n",
        "\n",
        "\n",
        "    # DNA Sequence Preprocessing\n",
        "    # Purpose: Turn DNA chunks into number lists for machine learning\n",
        "    # Steps:\n",
        "    # 1. Assign a unique number to each DNA chunk (up to 30,000 most common chunks)\n",
        "    # 2. Convert each DNA sequence to a list of these numbers tokens\n",
        "    # 3. Make all lists the same length (48) by adding zeros at the end if needed\n",
        "\n",
        "    # Example:\n",
        "    # Input DNA sequences:\n",
        "    #   [\"ATCG\", \"CGTA\", \"ATCGATCG\"]\n",
        "    #\n",
        "    # After assigning numbers:\n",
        "    #   ATCG -> 1, CGTA -> 2, GATC -> 3\n",
        "    #\n",
        "    # Converted to number lists:\n",
        "    #   [1, 2]\n",
        "    #   [2, 1]\n",
        "    #   [1, 3, 1]\n",
        "    #\n",
        "    # Final output (padded to length 48):\n",
        "    #   [1, 2, 0, 0, ..., 0]  (46 zeros)\n",
        "    #   [2, 1, 0, 0, ..., 0]  (46 zeros)\n",
        "    #   [1, 3, 1, 0, ..., 0]  (45 zeros)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words = 30000)\n",
        "    tokenizer.fit_on_texts(three_er_list)\n",
        "    sequences = tokenizer.texts_to_sequences(three_er_list)\n",
        "    sequences = pad_sequences(sequences, maxlen = 48, padding = \"post\")\n",
        "    sequences = np.array(sequences)\n",
        "\n",
        "\n",
        "    x_train,x_test = sequences[:pos_train_len],sequences[pos_train_len:]\n",
        "    # print(x_train)\n",
        "\n",
        "    y_train,y_test = test_labels[:pos_train_len],test_labels[pos_train_len:]\n",
        "\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3gJ9iRYWcIGI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masked_data(x_train, mask_percentage):\n",
        "    \"\"\"\n",
        "    Create a masked version of the input data.\n",
        "\n",
        "    Args:\n",
        "    x_train (numpy.ndarray): Input data to be masked.\n",
        "    mask_percentage (float): Percentage of data to be masked, between 0 and 1.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Masked version of the input data.\n",
        "    \"\"\"\n",
        "    # Validate mask_percentage range\n",
        "    if mask_percentage < 0.0 or mask_percentage > 1.0:\n",
        "        raise ValueError(\"mask_percentage must be between 0 and 1.\")\n",
        "\n",
        "    # Create a boolean mask: True with probability mask_percentage\n",
        "    mask = np.random.random(x_train.shape) < mask_percentage\n",
        "\n",
        "    # Apply the mask: keep original values where mask is False, set to 0 where mask is True\n",
        "    masked_data = np.where(mask, 0.0, x_train)\n",
        "\n",
        "    return masked_data"
      ],
      "metadata": {
        "id": "QX8EMxXOq3Xi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "x_train, x_test, y_train, y_test = prepare_training_data()\n",
        "# print(x_train)\n",
        "mask_percentage = 0.15  # Mask 15% of the data\n",
        "x_train = create_masked_data(x_train, mask_percentage)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbfCCTrycIYz",
        "outputId": "7a32efdc-2328-41ec-dc3a-62a5d8e0e3b0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 25 20 ...  0  0  0]\n",
            " [40 14 11 ...  0  0  0]\n",
            " [22 28 56 ...  0  0  0]\n",
            " ...\n",
            " [13 16  3 ...  0  0  0]\n",
            " [50 36 37 ...  0  0  0]\n",
            " [15 21 23 ...  0  0  0]]\n",
            "       0     1     2     3     4     5     6     7     8     9   ...    38  \\\n",
            "0     5.0  25.0  20.0  13.0  16.0  35.0   0.0   0.0   2.0   7.0  ...   4.0   \n",
            "1     0.0  14.0  11.0   4.0   0.0  20.0   0.0  14.0  50.0  29.0  ...  10.0   \n",
            "2    22.0  28.0  56.0  46.0  14.0  40.0  14.0  50.0  16.0   3.0  ...  26.0   \n",
            "3     5.0   2.0   2.0   2.0   0.0  51.0  36.0  19.0  15.0   0.0  ...  43.0   \n",
            "4    21.0  51.0  16.0   3.0  12.0  32.0  56.0  23.0   0.0  10.0  ...  26.0   \n",
            "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
            "361   0.0  27.0   3.0   0.0  14.0  33.0  22.0  28.0  26.0   7.0  ...   7.0   \n",
            "362   3.0   0.0   0.0  24.0  10.0  15.0  21.0  51.0  29.0  44.0  ...  16.0   \n",
            "363  13.0   0.0   3.0   1.0   1.0   1.0  13.0  64.0  57.0  50.0  ...  39.0   \n",
            "364  50.0  36.0  37.0   9.0   7.0   8.0   9.0  25.0   0.0  12.0  ...   6.0   \n",
            "365  15.0  21.0  23.0   5.0   0.0  31.0  38.0   0.0  31.0  38.0  ...  26.0   \n",
            "\n",
            "      39   40   41   42   43   44   45   46   47  \n",
            "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
            "361  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "362  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "363  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "364  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "365  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[366 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAXPEpY9utUK"
      },
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}